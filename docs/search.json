[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog! This is something I started as a challenge at the beginning of my fall break, to document my learnings as much as I can."
  },
  {
    "objectID": "posts/0-pytorch-coding-solutions/index.html",
    "href": "posts/0-pytorch-coding-solutions/index.html",
    "title": "Solutions to PyTorch Coding Assignments - Oct 4, 2023",
    "section": "",
    "text": "Let’s import the dependencies first.\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom torch.nn.functional import relu\n\nTask 1: Recode Encoder 1 so that: - Basic block output is 32x128x128 - Conv2D output is 32x64x64\n\nclass UNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        \n        # Encoder\n        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image. \n        # Each block in the encoder consists of two convolutional layers followed by a max-pooling layer, with the exception of the last block which does not include a max-pooling layer.\n        # -------\n        # input: 572x572x3\n        self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1) # output: 570x570x64\n        self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1) # output: 568x568x64\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 284x284x64\n\n        # input: 284x284x64\n        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 282x282x128\n        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 280x280x128\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n\n        # input: 140x140x128\n        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 138x138x256\n        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 136x136x256\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n\n        # input: 68x68x256\n        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 66x66x512\n        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 64x64x512\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n\n        # input: 32x32x512\n        self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) # output: 30x30x1024\n        self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1) # output: 28x28x1024\n\n\n        # Decoder\n        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n        self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n\n        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n        self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n\n        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n        self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n\n        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n\n        # Output layer\n        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n\nTask 2: Recode U-Net so that there are 5 encoder/decoder blocks\nTask 3: Recode sigmoid output so that it is for atrons 3x3 + 5x5 + 7x7"
  },
  {
    "objectID": "posts/x-days-of-code/index.html#day-0-basic-pytorch-syntax-review",
    "href": "posts/x-days-of-code/index.html#day-0-basic-pytorch-syntax-review",
    "title": "X Days of Code Challenge",
    "section": "Day 0: Basic PyTorch Syntax Review",
    "text": "Day 0: Basic PyTorch Syntax Review\nBefore you try to run any of the code below, make sure to import the dependencies using the following lines:\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nOne-Hot Encoding\nUsed for converting categorical data into numeric. The basic idea behind this is that we can convert one column with x categories into x no. of columns with value of either a 0 or 1, each column representing whether or not the initial value fell into that category.\nHere’s how we implement it in PyTorch:\n\ntorch.tensor()\n\nF.one_hot()\n\n\n\nSigmoid and Softmax Functions\nThese are both activation functions, normally used as a final layer in a neural network. The most considerable difference between the two is the fact that Sigmoid deals with one-dimensional input & output, whereas the Softmax deals with milti-dimensional inputs - mostly in multi-class classification problems. Let’s learn more about each of them:\n\\[Sigmoid = \\dfrac{1}{1+exp(-x)}\\]\n\\[\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\\]"
  },
  {
    "objectID": "posts/2-autograd-from-scratch/index.html",
    "href": "posts/2-autograd-from-scratch/index.html",
    "title": "Implementing Autograd Engine from Scratch",
    "section": "",
    "text": "In an attempt of understanding the underlying mechanism of PyTorch’s autograd engine, I created its mini-version that does the same job, but on a much lower scale. This blog post explains the core ideas behind that project. This is mostly just to test my own understanding - yet again. But if you gain any knowledge from this, I’d be glad. Let’s get started!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ayush Raj’s blog",
    "section": "",
    "text": "Stochastic Gradient Descent from Scratch\n\n\n\n\n\n\n\nNeural Networks\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2023\n\n\nAyush Raj Dahal\n\n\n\n\n\n\n  \n\n\n\n\nX Days of Code Challenge\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\nAyush Raj Dahal\n\n\n\n\n\n\n  \n\n\n\n\nImplementing Autograd Engine from Scratch\n\n\n\n\n\n\n\nNeural Networks\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\nAyush Raj Dahal\n\n\n\n\n\n\n  \n\n\n\n\nSolutions to PyTorch Coding Assignments - Oct 4, 2023\n\n\n\n\n\n\n\nPyTorch\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nAyush Raj Dahal\n\n\n\n\n\n\nNo matching items"
  }
]