{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"X Days of Code Challenge\"\n",
    "author: \"Ayush Raj Dahal\"\n",
    "date: \"2023-10-07\"\n",
    "categories: [Programming]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](thumbnail.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 0: Basic PyTorch Syntax Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you try to run any of the code below, make sure to import the dependencies using the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for converting categorical data into numeric. The basic idea behind this is that we can convert one column with x categories into x no. of columns with value of either a 0 or 1, each column representing whether or not the initial value fell into that category.\n",
    "\n",
    "Here's how we implement it in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor()\n",
    "\n",
    "F.one_hot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid and Softmax Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are both activation functions, normally used as a final layer in a neural network. The most considerable difference between the two is the fact that Sigmoid deals with one-dimensional input & output, whereas the Softmax deals with milti-dimensional inputs - mostly in multi-class classification problems. Let's learn more about each of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Sigmoid = \\dfrac{1}{1+exp(-x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
